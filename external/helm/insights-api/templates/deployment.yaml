apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.envName }}-insights-api
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/name: insights-api
    app.kubernetes.io/instance: {{ .Values.envName }}-insights-api
    app.kubernetes.io/version: {{ .Chart.Version }}
    app.kubernetes.io/managed-by: "Helm"
    stage: {{ .Values.envName }}
  annotations:
    meta.helm.sh/release-name: {{ .Release.Name }}
    meta.helm.sh/release-namespace: {{ .Release.Namespace }}
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: insights-api
      app.kubernetes.io/instance: {{ .Values.envName }}-insights-api
      #don't add app.kubernetes.io/version
      app.kubernetes.io/managed-by: "Helm"
      stage: {{ .Values.envName }}
  replicas: {{ .Values.replicas }}
  #TODO affinity/antiAffinity?
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: insights-api
        app.kubernetes.io/instance: {{ .Values.envName }}-insights-api
        app.kubernetes.io/version: {{ .Chart.Version }}
        app.kubernetes.io/managed-by: "Helm"
        stage: {{ .Values.envName }}
      annotations:
        meta.helm.sh/release-name: {{ .Release.Name }}
        meta.helm.sh/release-namespace: {{ .Release.Namespace }}
        rollme: {{ randAlphaNum 5 | quote }} #random value that makes Helm restart pods on any upgrade
    spec:
      containers:
        - name: insights-api
          image: nexus.kontur.io:8085/konturdev/insights-api:{{ .Chart.Version }}
          imagePullPolicy: Always #don't use Always for local minikube - otherwise it tries reloading from remote
          resources:
            requests:
              cpu: "1"
              memory: "6G"
            limits:
              memory: "12G"
          env:
            - name: OTEL_SERVICE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.labels['app.kubernetes.io/instance']
            - name: MY_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: http://$(MY_NODE_NAME):4317
          envFrom:
            - configMapRef:
                name: {{ .Values.envName }}-insights-api
            - secretRef:
                name: {{ .Values.envName }}-insights-api #TODO must contain SPRING_DATASOURCE_PASSWORD
          readinessProbe:
            httpGet:
              path: /insights-api/health/readiness
              port: 8625
            failureThreshold: 1
            periodSeconds: 60
            initialDelaySeconds: 30
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.envName }}-insights-api-redis
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/name: insights-api-redis
    app.kubernetes.io/instance: {{ .Values.envName }}-insights-api-redis
    app.kubernetes.io/version: {{ .Chart.Version }}
    app.kubernetes.io/managed-by: "Helm"
    stage: {{ .Values.envName }}
  annotations:
    meta.helm.sh/release-name: {{ .Release.Name }}
    meta.helm.sh/release-namespace: {{ .Release.Namespace }}
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: insights-api-redis
      app.kubernetes.io/instance: {{ .Values.envName }}-insights-api-redis
      #don't add app.kubernetes.io/version
      app.kubernetes.io/managed-by: "Helm"
      stage: {{ .Values.envName }}
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/name: insights-api-redis
        app.kubernetes.io/instance: {{ .Values.envName }}-insights-api-redis
        app.kubernetes.io/version: {{ .Chart.Version }}
        app.kubernetes.io/managed-by: "Helm"
        stage: {{ .Values.envName }}
      annotations:
        meta.helm.sh/release-name: {{ .Release.Name }}
        meta.helm.sh/release-namespace: {{ .Release.Namespace }}
        rollme: {{ randAlphaNum 5 | quote }} #random value that makes Helm restart pods on any upgrade
    spec:
      volumes:
        - name: start-scripts
          configMap:
            name: {{ .Values.envName }}-insights-api-redis-scripts
            defaultMode: 493
        - name: health
          configMap:
            name: {{ .Values.envName }}-insights-api-redis-health
            defaultMode: 493
        - name: config
          configMap:
            name: {{ .Values.envName }}-insights-api-redis-configuration
            defaultMode: 420
        - name: redis-tmp-conf
          emptyDir: {}
        - name: tmp
          emptyDir: {}
        - name: redis-data
          emptyDir: {}
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.0.3-debian-11-r0
          command:
            - /bin/bash
          args:
            - '-c'
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          ports:
            - name: redis
              containerPort: 6379
              protocol: TCP
          env:
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: 'no'
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis
                  key: redis-password
            - name: REDIS_TLS_ENABLED
              value: 'no'
            - name: REDIS_PORT
              value: '6379'
          resources:
            requests:
              cpu: "100m"
              memory: "512M"
            limits:
              memory: "1G"
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: redis-tmp-conf
              mountPath: /opt/bitnami/redis/etc/
            - name: tmp
              mountPath: /tmp
          livenessProbe:
            exec:
              command:
                - sh
                - '-c'
                - /health/ping_liveness_local.sh 5
            initialDelaySeconds: 20
            timeoutSeconds: 6
            periodSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          readinessProbe:
            exec:
              command:
                - sh
                - '-c'
                - /health/ping_readiness_local.sh 1
            initialDelaySeconds: 20
            timeoutSeconds: 2
            periodSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          imagePullPolicy: IfNotPresent
        - name: redis-exporter
          image: oliver006/redis_exporter:v1.43.0
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
            - name: metrics
              protocol: TCP
              containerPort: 9121
          env:
            - name: REDIS_ADDR
              value: redis://localhost:6379
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis
                  key: redis-password
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
---